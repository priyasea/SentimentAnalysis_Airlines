{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30170e5c-4592-4fd8-a7be-15e39834afb9",
   "metadata": {},
   "source": [
    "# Airline Tweets Sentiment Analysis using Machine Learning  \n",
    "### Predicting the sentiment in tweets as Positive/Negative with LinearSVC & FastAPI | Dockerized & Deployed on Render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcefc71-a073-4a57-a996-fe9e72dabcc2",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "When people complete their journeys on airplanes, they tweet about it upon landing or reaching their homes. These tweets can tell about a positive experience or negative experience with the flight carrier. The Airlines operating the flight have to scan through these tweets and determine which are the negative ones and respond to them accordingly assuring of better service next time or any amendments. \n",
    "This machine learning project will help Airlines to identify negative reviews and take appropriate steps for improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e199ea98-d9b8-48e3-8c66-d190ef6ee778",
   "metadata": {},
   "source": [
    "The objective of this project is to develop a machine learning–based Airline Tweets Sentiment Analysis Prediction system that predicts whether the tweet is positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e740c1f-4e0d-4ade-b0aa-32120b05964d",
   "metadata": {},
   "source": [
    "The project includes:\n",
    "\n",
    "- Data cleaning and preprocessing\n",
    "- Exploratory Data Analysis (EDA)  \n",
    "- Feature engineering and selection\n",
    "- Model training and comparison (Logistic Regression, LinearSVC, Complimentary Naive Bayes)  \n",
    "- Hyperparameter tuning\n",
    "- Training final model\n",
    "- Deploying the model using FastAPI and Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d3091c-5956-4bd0-9a55-bb0a93dcf906",
   "metadata": {},
   "source": [
    "The final solution is built using the LinearSVC model as we got best F1 score with this model\n",
    "\n",
    "The model is deployed as a REST API using FastAPI, containerized using Docker, and hosted on Render for real-time inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2aaeda-5446-4e9f-9544-b20d112eae3e",
   "metadata": {},
   "source": [
    "## How the Solution Is Used\n",
    "\n",
    "### 1. Transaction Prediction \n",
    "\n",
    "When a transaction is processed, its details are sent to the `/predict` endpoint. The API responds with sentiment labels and classification. \n",
    "\n",
    "#### Example request:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "  \"text\": \"It was not at all a good flight. We were stranded at Frankfurt which was a stopover\",\n",
    "  \"airline\": \"american\",\n",
    "  \"retweet_count\": 0\n",
    "}\n",
    "\n",
    "]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e310173-a692-4441-b1d8-ef33c45d7c2c",
   "metadata": {},
   "source": [
    "#### Example Response\n",
    "```json\n",
    "\n",
    "{\n",
    "  \"sentiment\": 0,\n",
    "  \"tweet\": \"Negative tweet\"\n",
    "}\n",
    "\n",
    "```\n",
    "Based on the model response:\n",
    "\n",
    "| Prediction                      | Recommended Action       |\n",
    "|---------------------------------|--------------------------|\n",
    "| Negative Tweet                 | Take action for improvement/apology\n",
    "| Positive Tweet                 | Thank customer                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80809ba2-c174-4106-920c-b2981f9899bb",
   "metadata": {},
   "source": [
    "### Summary of integration\n",
    "\n",
    "- Supports real-time sentiment prediction\n",
    "- Returns a class 1/0 and tweet prediction\n",
    "- Suitable for integration with realtime Twitter Reviews of airlines \n",
    "- Helps airlines improve their services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93cab80-1330-4228-9972-a40c1bd3c92e",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) before Feature Engineering\n",
    "\n",
    "### 1. Dataset Overview\n",
    "\n",
    "- **Total transactions:** `4008`\n",
    "- **Positive Reviews:** `1781` (~44.43%)\n",
    "- **Negative Reviews:** `2227` (~55.56%)\n",
    "- **Missing values:** `user_timezone : 1280`\n",
    "\n",
    "**Data source:** [Airline Sentiment Prediction Dataset(Kaggle)]  \n",
    "(https://www.kaggle.com/competitions/bootcamp-the-basics-of-mla/data)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Feature Overview\n",
    "\n",
    "| Feature Type | Features |\n",
    "|--------------|----------|\n",
    "| **Identifier** | `Id`|\n",
    "| **Numerical** | `retweet_count` |\n",
    "| **Non Numeric** | `airline`, `text`, `user_timezone` |\n",
    "| **Target variable** | `airline_sentiment` (positive = Positive Tweet ,negative = Negative Tweet) |\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Class Distribution (Class Imbalance)\n",
    "\n",
    "The target variable is slightly imbalanced:\n",
    "- **Positive Tweets:** `1781`\n",
    "- **Negative Tweets:** `2227`\n",
    "\n",
    "**Image in repository at:** `images/class_distribution.png`\n",
    "\n",
    "![Sentiment Prediction Counts](images/class_distribution.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671a5bb-810a-47e4-b13b-cb3ddb9aa7e0",
   "metadata": {},
   "source": [
    "\n",
    "**Key insight:**\n",
    "- Accuracy is not sufficient to judge the models → we focused on **F1-score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93684fb-cd17-4bd9-b93c-e22de7a4871a",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We encoded the airline_sentiment feature which was a categorical feature into numeric feature called sentiment as follows<br>\n",
    "`df[\"sentiment\"] = (df[\"airline_sentiment\"] == \"positive\").astype(int)`\n",
    "\n",
    "It was necessary to encode most important feature which is **text** certain into numeric to capture general characteristics of negative tweets . \n",
    "Some features were dropped as they were not influencing the Sentiment Variable.\n",
    "Feature enginering has been done for EDA within the notebook. <br>\n",
    "The `FeatureEngineering` is implemented  **src/feature_engineering.py**. This transformation is applied as the first step of the ML pipeline \n",
    "to ensure consistency during both training and inference.\n",
    "\n",
    "### Key Transformations\n",
    "\n",
    "| Feature | Description | Motivation |\n",
    "|--------|-------------|------------|\n",
    "| `airline_sentiment`|`sentiment` | Airline Sentiment is encoded into binary numeric feature 0/1 |\n",
    "| `text` |`text_length`| text_length is a numeric feature derived from text which is the number of characters in tweet. |\n",
    "| `text` | `word_count` |word_count is a numeric feature derived from text which is the number of words in tweet. |\n",
    "| `text` | `neg_word_count` |neg_word_count is a numeric feature derived from text which is the number of negative words in tweet. |\n",
    "| `text` | `all_caps_count` |all_caps_count is a numeric feature derived from text which is the number of words in CAPS in tweet. |\n",
    "| `text` | `exclamations` |exclamations is a numeric feature derived from text which is the number of exclamations in tweet. |\n",
    "| `text` | `has_negation` |has_negation is a numeric(binary) feature derived from text which indicates presence of negation like no/not/never etc. |\n",
    "| **Dropped:** `Id`| Removed unique identifiers | Prevent data leakage and overfitting |\n",
    "| **Dropped:** `user_timezone` | Has negligible impact on target variable | Has many missing values |\n",
    "| **Dropped:** `airline`|May have slight impact on target variable| removed this feature to not introduce bias for an airline|\n",
    "| **Dropped:** `airline_sentiment`|This is target variable encoded as new target variable **sentiment**|redundant feature|\n",
    "### Why This Matters\n",
    "\n",
    "- Most machine-learning algorithms operate on numbers, not labels or strings.\n",
    "- We used Text feature to derive several numeric features like text_length, neg_word_count so that model learns characteristic features of negative and positive tweets\n",
    "- Prevents **data leakage** by excluding unique identifiers\n",
    "- Dropped columns like airline and user_timezone so that model can be built on important features.\n",
    "- Converted Target Variable airline_sentiment into numneric binary feature sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344bb41-9feb-4552-a890-5db550a878c3",
   "metadata": {},
   "source": [
    "## EDA after Feature Engineering \n",
    "\n",
    "Due to limited features, we did EDA after feature engineering as follows:-\n",
    "\n",
    "\n",
    "#### 1. Average Text Count by Sentiment\n",
    "**Image in repository at:** `images/Average Text Length (characters) by Sentiment.png`\n",
    "\n",
    "![Average Text Length](<images/Average Text Length (characters) by Sentiment.png>)\n",
    "\n",
    "#### 2. Average Word Count by Sentiment\n",
    "**Image in repository at:** `images/Average Word Count by Sentiment.png`\n",
    "\n",
    "![Average Word Count](<images/Average Word Count by Sentiment.png>)\n",
    "\n",
    "#### 3. Average Exclamation Count by Sentiment\n",
    "**Image in repository at:** `images/Average Exclamation Count by Sentiment.png`\n",
    "\n",
    "![Average Exclamation Count](<images/Average Exclamation Count by Sentiment.png>)\n",
    "\n",
    "#### 4. Average Negative Word Count by Sentiment\n",
    "**Image in repository at:** `images/Average Negative Word Count by Sentiment.png`\n",
    "\n",
    "![Average Negative Word Count](<images/Average Negative Word Count by Sentiment.png>)\n",
    "\n",
    "\n",
    "#### 5. Text Distribution \n",
    "**Image in repository at:** `images/text_length_distribution.png`\n",
    "\n",
    "![Text Length Distribution](images/text_length_distribution.png)\n",
    "\n",
    "#### 6. Word Count Distributuon \n",
    "**Image in repository at:** `images/word_count_distribution.png`\n",
    "\n",
    "![Word Count Distribution](images/word_count_distribution.png)\n",
    "\n",
    "#### 7. Word Cloud Positive Tweets/Reviews\n",
    "**Image in repository at:** `images/Word_Cloud_by_positive_sentiment.png`\n",
    "\n",
    "![Positive Sentiment Word Cloud](images/Word_Cloud_by_positive_sentiment.png)\n",
    "\n",
    "\n",
    "#### 8. Word Cloud Negative Tweets/Reviews\n",
    "**Image in repository at:** `images/Word_Cloud_by_negative_sentiment.png`\n",
    "\n",
    "![Word Count Distribution](images/Word_Cloud_by_negative_sentiment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fe433-ea5f-478d-b52d-22279eceb944",
   "metadata": {},
   "source": [
    "#### 9. (Categorical/Binary Features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5524630-1044-46e9-af37-21069594a71f",
   "metadata": {},
   "source": [
    "### 5. Correlation of Numeric Features\n",
    "\n",
    "**Image in repository:** `images/correlation_matrix.png`\n",
    "\n",
    "![Correlation Matrix of Numeric Features](images/correlation_matrix.png)\n",
    "\n",
    "**Important correlations with `sentiment`:**\n",
    "- `text_length`    →  -0.389326\n",
    "- `word_count`     → -0.398904\n",
    "- `exclamations`   →  0.268645\n",
    "- `neg_word_count` → -0.276611\n",
    "- `all_caps_count` → 0.020483\n",
    "- `retweet_count`  → -0.027942   \n",
    "\n",
    "#### Interpretation:\n",
    "* **More Text Length** → More likely to be Negative Review as people rant about negative experiences\n",
    "* **More Word Count** → More likely to be Negative Review\n",
    "* **More exclamations** →Likely to be Positive Review\n",
    "* **More Negative Word Count** → Most likely to be Negative Review\n",
    "* **All Capital Words** →Likely to be Positive Review\n",
    "* **Retweet Count** → More likely to be Negative Review as negative experience is retweeted to gather attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acb7af-3292-4ac5-828d-f7071ca7a6e4",
   "metadata": {},
   "source": [
    "## Model Training & Selection\n",
    "\n",
    "The dataset was split into:\n",
    "* 60% Training\n",
    "* 20% Validation\n",
    "* 20% Testing\n",
    "\n",
    "Multiple models were trained using the training set and evaluated against the validation set. Hyperparameter tuning and threshold optimization were performed to maximize predictive performance, especially focusing on F1-score .\n",
    "\n",
    "### Models Evaluated\n",
    "\n",
    "| Model | Tuned Parameters | Decision Threshold | F1 Score | Precision | Recall |\n",
    "|-------|------------------|-------------------|---------|-----------|----------|\n",
    "| Logistic Regression | `C': 10, 'penalty': 'l2'` | 0.45 | 0.822259 | 0.765586 | 0.86236 | \n",
    "| Linear SVC| `'C':0.1,'class_weight':'balanced'` | NA | 0.851909   | 0.82  | 0.86 |\n",
    "| Complementary Naive Baiyes | `'alpha': 0.1` | NA |0.84 | 0.83\t | 0.79\t |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e688e2-b1ae-41bf-bb7b-644ec75ff735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b981f50b-ec00-48e9-9ac9-c7adf087d387",
   "metadata": {},
   "source": [
    "### Final Model Selection\n",
    "\n",
    "After comparing performance across models, **LinearSVC** was selected as the final production model based on the following:\n",
    "\n",
    "* Highest F1 Score on validation  \n",
    "* Best overall Recall and Precision\n",
    "\n",
    "### Pipeline Integration\n",
    "The transformer is used as part of the final ML pipeline:\n",
    "```python\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"feature_engineering\", FeatureEngineering()),\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"classifier\", LinearSVC(\n",
    "                        C=0.1,\n",
    "                        class_weight=\"balanced\",\n",
    "                        random_state=42\n",
    "                            ))\n",
    "    ]\n",
    "```\n",
    "## Exporting Notebook to Script\n",
    "\n",
    "To comply with project requirements and ensure reproducibility, all essential machine learning steps developed in the notebook (`notebooks/notebook.ipynb`) were fully converted into Python scripts.\n",
    "\n",
    "### Scripts Created\n",
    "\n",
    "| Script | Purpose |\n",
    "|--------|---------|\n",
    "| `src/train.py` | Contains final model training pipeline and saves the trained model. |\n",
    "| `src/predict.py` | Loads the trained model and serves predictions via a FastAPI REST endpoint. |\n",
    "| `src/feature_engineering.py` | Implements the custom feature engineering logic. |\n",
    "\n",
    "### What Was Exported from Notebook\n",
    "The following core logic developed and validated in `notebooks/notebook.ipynb` was migrated into standalone scripts for production readiness:\n",
    "\n",
    "| Exported Component | Implemented In | Description |\n",
    "|-------------------|----------------|-------------|\n",
    "| Data loading | `train.py` | Reads sentiment dataset from `data/airline_tweets_train.csv`. |\n",
    "| Feature engineering logic | `feature_engineering.py` | Custom transformer class `FeatureEngineering`. |\n",
    "| Model training & hyperparameter tuning | `train.py` | Uses tuned LinearSVC model parameters finalized from notebook experiments. |\n",
    "| Final model training | `train.py` | Trains LinearSVC model on entire training dataset. |\n",
    "| Model serialization (pipeline) | `train.py` | Saved using `pickle` as `models/model.pkl`. |\n",
    "| API-based prediction logic | `predict.py` | Loads trained pipeline and serves predictions via FastAPI. |\n",
    "\n",
    "### Example: Model Saving in `train.py`\n",
    "```python\n",
    "model_path = \"models/model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "### \n",
    "Example: Model Loading in `predict.py`\n",
    "```python\n",
    "MODEL_PATH = \"models/model.pkl\"\n",
    "BASE_DIR = Path(__file__).resolve().parent.parent\n",
    "with open(MODEL_PATH, \"rb\") as f_in:\n",
    "    pipeline = pickle.load(f_in)\n",
    "```\n",
    "\n",
    "## Reproducibility\n",
    "\n",
    "This project is fully reproducible. The dataset, notebook, and training scripts are included in the repository, allowing seamless re-execution.\n",
    "\n",
    "- Dataset available in `data/airline_tweets_train.csv`\n",
    "- Full analysis in `notebooks/notebook.ipynb`\n",
    "- Feature Training function in `src/feature_engineering.py`\n",
    "- Final model training located in `src/train.py`\n",
    "- Inference logic exposed via `src/predict.py`\n",
    "- Trained pipeline saved at `models/model.pkl`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4db45b-d86c-49c6-bd23-c2cf7939538b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### How to Reproduce\n",
    "```bash\n",
    "# Install dependencies and set up environment\n",
    "uv sync\n",
    "\n",
    "# Run training script\n",
    "uv run python -m src.train\n",
    "\n",
    "# Start FastAPI server\n",
    "uv run uvicorn src.predict:app --reload --port 8000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Model Deployment (Local)\n",
    "\n",
    "The trained machine learning model is deployed locally using **FastAPI** and served via **Uvicorn**.\n",
    "\n",
    "### Start API Locally\n",
    "```bash\n",
    "uv run uvicorn src.predict:app --reload --port 8000\n",
    "```\n",
    "\n",
    "Once the application is running:\n",
    "\n",
    "- **Swagger UI (API documentation):** `http://localhost:8000/docs`\n",
    "- **Root endpoint:** `http://localhost:8000/`\n",
    "\n",
    "### Supported Features\n",
    "- **Airline Tweets Sentiment Prediction API (POST):** `/predict` \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b006255-bdf3-4277-9369-841dd5ed1d59",
   "metadata": {},
   "source": [
    "## Dependency & Environment Management\n",
    "\n",
    "The project uses **uv** to manage dependencies and execution. All required packages are defined in `pyproject.toml` and `requirements.txt`.\n",
    "\n",
    "### Install Dependencies\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "### Example Execution Commands\n",
    "```bash\n",
    "uv run python -m src.train      # Train model\n",
    "uv run uvicorn src.predict:app --reload --port 8000   # Launch API\n",
    "```\n",
    "---\n",
    "\n",
    "## Dependency Files\n",
    "\n",
    "### `requirements.txt`\n",
    "```txt\n",
    "fastapi==0.128.0\n",
    "joblib==1.5.3\n",
    "numpy==2.4.0\n",
    "pandas==2.3.3\n",
    "pydantic==2.12.5\n",
    "pydantic_core==2.41.5\n",
    "scikit-learn==1.8.0\n",
    "scipy==1.16.3\n",
    "seaborn==0.13.2\n",
    "uv==0.9.21\n",
    "uvicorn==0.40.0\n",
    "\n",
    "```\n",
    "\n",
    "### `pyproject.toml`\n",
    "```toml\n",
    "[project]\n",
    "name = \"sentimentanalysis-airlines\"\n",
    "version = \"0.1.0\"\n",
    "description = \"Tp predict the Sentiment class\"\n",
    "readme = \"README.md\"\n",
    "requires-python = \">=3.12\"\n",
    "dependencies = [\n",
    "    \"fastapi>=0.128.0\",\n",
    "    \"pandas>=2.3.3\",\n",
    "    \"scikit-learn>=1.8.0\",\n",
    "    \"uvicorn>=0.40.0\",\n",
    "    \"xgboost>=3.1.2\",\n",
    "    \"pydantic>=2.12.5\",\n",
    "    \"pydantic_core>=2.41.5\",\n",
    "    \"numpy>=2.4.0\",\n",
    "    \"pandas>=2.3.3\",\n",
    "    \"scipy==1.16.3\",\n",
    "    \"notebook>=7.5.1\",\n",
    "]\n",
    "\n",
    "[dependency-groups]\n",
    "dev = [\n",
    "    \"requests>=2.32.5\",\n",
    "]\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "## Containerization (Docker)\n",
    "\n",
    "The project is fully containerized using **Docker**, allowing consistent deployment across environments.\n",
    "\n",
    "### Dockerfile Used\n",
    "```dockerfile\n",
    "FROM python:3.12-slim\n",
    "\n",
    "# ==============================\n",
    "# Environment settings\n",
    "# ==============================\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "# ==============================\n",
    "# Working directory\n",
    "# ==============================\n",
    "WORKDIR /app\n",
    "\n",
    "# ==============================\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    build-essential \\\n",
    "    libgomp1 \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# ==============================\n",
    "# Python dependencies\n",
    "# ==============================\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Copy only required files\n",
    "# ==============================\n",
    "COPY src ./src\n",
    "COPY models ./models\n",
    "\n",
    "# ==============================\n",
    "# Expose API port\n",
    "# ==============================\n",
    "EXPOSE 8000\n",
    "\n",
    "# ==============================\n",
    "# Run FastAPI\n",
    "# ==============================\n",
    "CMD [\"uvicorn\", \"src.predict:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\n",
    "```\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c06c6-6cdc-4b1a-87cb-b77b503675ae",
   "metadata": {},
   "source": [
    "### Build the Docker Image\n",
    "\n",
    "Run the following command inside the project folder:\n",
    "```bash\n",
    "docker build -t airline-sentiment-api .\n",
    "```\n",
    "---\n",
    "\n",
    "### Run the Docker Container\n",
    "```bash\n",
    "docker run -p 8000:8000 airline-sentiment-api\n",
    "```\n",
    "\n",
    "Once started, the API will be available at:\n",
    "- **Local URL** → `http://localhost:8000/docs/`\n",
    "- **Swagger UI** → `http://localhost:8000/docs/`\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf08d7ba-df22-4bc8-811d-527c47072fe2",
   "metadata": {},
   "source": [
    "## Cloud Deployment\n",
    "\n",
    "The Airline Tweets Sentiment Prediction API is deployed on Render using FastAPI and Docker, enabling real-time sentiment class inference through RESTful endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313963e8-6107-4a82-afad-b6aecbdadd2c",
   "metadata": {},
   "source": [
    "### Deployment Steps (Docker + Render)\n",
    "\n",
    "#### 1. Push complete project to GitHub\n",
    "[github repo link]\n",
    "(https://github.com/priyasea/SentimentAnalysis_Airlines)\n",
    "\n",
    "\n",
    "#### 2. On Render Dashboard → “New Web Service”\n",
    "\n",
    "#### 3. Select Deployment Settings\n",
    "\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| Environment |\tDocker |\n",
    "| Repository | `priyasea/SentimentAnalysis_Airlines` |\n",
    "| Branch | main |\n",
    "| Root Directory | `(leave empty)` |\n",
    "| Environment Variables | `PORT=8000` |\n",
    "| Instance Type | Free Tier |\n",
    "\n",
    "#### 4. Click \"Deploy Web Service\"\n",
    "\n",
    "Render automatically:\n",
    "\n",
    "* Pulls repo\n",
    "\n",
    "* Builds Docker image\n",
    "\n",
    "* Runs FastAPI service using command from Dockerfile\n",
    "```CSS\n",
    "CMD [\"uvicorn\", \"src.predict:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c0566-727c-4b4b-8038-a53eb5dc8ab9",
   "metadata": {},
   "source": [
    "##  Proof of Successful Deployment\n",
    "\n",
    "### Render Deployment Configuration\n",
    "![Deployment video Predict api](images/Cloud_Deployment/LoanPredictionAPI_Render.mp4)\n",
    "![Deployment video HTML UI](images/Cloud_Deployment/LoanPredictionHTML_Render.mp4)             \n",
    "![Deployment Pic](images/Cloud_Deployment/LoanPrediction_mainRender.png)\n",
    "\n",
    "\n",
    "### API Testing Examples\n",
    "\n",
    "#### 1. Single Transaction (POST /predict)\n",
    "\n",
    "##### Request\n",
    "\n",
    "![API request](images/Cloud_Deployment/loanpredict_request.png)\n",
    "\n",
    "```json\n",
    "\n",
    "{\n",
    "  \"employment_status\": \"employed\",\n",
    "  \"education_level\": \"bachelors\",\n",
    "  \"grade_subgrade\": \"a1\",\n",
    "  \"loan_purpose\": \"business\",\n",
    "  \"credit_score\": 650,\n",
    "  \"annual_income\": 120000,\n",
    "  \"debt_to_income_ratio\": 0.4,\n",
    "  \"loan_amount\": 40000,\n",
    "  \"interest_rate\": 13\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "##### Response:\n",
    "\n",
    "![API request](images/Cloud_Deployment/loanpredict_response.png)\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"loan_paid_back_probability\": 0.3745,\n",
    "  \"loan_paid_back\": \"Loan will not be paid back\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19584623-1465-4e64-8c88-64d34f8d4d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
